# ğŸ‘ï¸ Gaze Tracking System

A hybrid **Gaze Tracking System** that captures and analyzes human eye gaze using **OpenCV** and **MediaPipe**.  
This system supports both **manual point calibration** and **automatic calibration**, combining **head pose** and **eye gaze** data for accurate gaze estimation.

---

## ğŸš€ Features

- ğŸ¥ **Real-Time Face & Eye Tracking** â€” Tracks face landmarks and iris in real-time using MediaPipe.
- ğŸ§  **Hybrid Fusion Engine** â€” Combines head pose and eye gaze vectors for robust gaze estimation.
- âš™ï¸ **Calibration Modes**
  - **Point Calibration** (Manual)
  - **Automatic Calibration** (Adaptive)
- ğŸ“Š **Visualization** â€” Displays gaze direction, calibration points, and tracking lines.
- ğŸª¶ **Lightweight** â€” CPU-optimized, runs on standard webcams.
- ğŸ“ **Data Logging** â€” Stores gaze data for research and analysis.

---

## ğŸ§© System Architecture

```mermaid
flowchart TD
    A[Camera Input] --> B[MediaPipe Face Mesh]
    B --> C[Landmark Extraction]
    C --> D[Head Pose Estimation]
    C --> E[Eye Feature Extraction]
    C --> F[Iris Detection]
    D --> G[Head Gaze Vector]
    E --> H[Eye Gaze Vector]
    F --> H
    G --> I[Hybrid Fusion Engine]
    H --> I
    I --> J[Gaze Estimation Output]
    J --> K[Visualization & Logging]
ğŸ› ï¸ Installation
1ï¸âƒ£ Clone the Repository
bash
Copy code
git clone https://github.com/yourusername/gaze-tracking-system.git
cd gaze-tracking-system
2ï¸âƒ£ Create Virtual Environment (Optional)
bash
Copy code
python -m venv venv
# Activate it
venv\Scripts\activate        # On Windows
source venv/bin/activate     # On macOS/Linux
3ï¸âƒ£ Install Dependencies
bash
Copy code
pip install -r requirements.txt
ğŸ“¦ Requirements
Include these in your requirements.txt file:

Copy code
opencv-python
mediapipe
numpy
(Optional for advanced features:)

nginx
Copy code
pandas
matplotlib
scikit-learn
scipy
â–¶ï¸ Usage
Run the Gaze Tracker
bash
Copy code
python gaze_tracker.py
Controls
Key	Action
c	Start/Stop Calibration
m	Switch to Manual Point Calibration
a	Switch to Automatic Calibration
q	Quit Program

ğŸ§  Working Principle
Face & Eye Detection â€” MediaPipe detects 3D facial landmarks and iris positions.

Head Pose Estimation â€” Uses key facial landmarks to compute head orientation.

Eye Gaze Vector â€” Derived from the iris center and eye landmarks.

Hybrid Fusion â€” Combines eye and head vectors for stable gaze direction.

Calibration â€” Maps gaze direction to screen coordinates.

Visualization â€” Displays tracking overlay, calibration dots, and gaze estimation lines.

ğŸ—‚ï¸ Folder Structure
perl
Copy code
ğŸ“ gaze-tracking-system
â”‚
â”œâ”€â”€ gaze_tracker.py           # Main script
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ utils/
    â”œâ”€â”€ calibration.py        # Calibration module
    â”œâ”€â”€ fusion.py             # Hybrid fusion logic
    â”œâ”€â”€ visualization.py      # Real-time drawing functions
    â””â”€â”€ logger.py             # CSV logging utilities
ğŸŒŸ Future Enhancements
ğŸ”¥ Heatmap visualization for gaze concentration

ğŸ“ˆ Real-time analytics dashboard

ğŸ§© Deep learningâ€“based gaze refinement

ğŸ’» Web-based gaze tracking (WebGazer.js integration)

ğŸ¯ Gaze-controlled interface for accessibility

ğŸ§‘â€ğŸ’» Author
Bala Ji
ğŸ’¼ Victo Hosting | Victo Interns
ğŸŒ victointern.site

ğŸ“„ License
This project is licensed under the MIT License.
Youâ€™re free to use, modify, and distribute it with attribution.

ğŸ™Œ Acknowledgements
MediaPipe by Google

OpenCV

WebGazer.js (concept inspiration)

