# ğŸ‘ï¸ Gaze Tracking System

A hybrid **Gaze Tracking System** that captures and analyzes human eye gaze using **OpenCV** and **MediaPipe**.  
It supports both **manual point calibration** and **automatic calibration**, combining **head pose** and **eye gaze** data for accurate gaze estimation.

---

## ğŸš€ Features

- ğŸ¥ **Real-Time Face & Eye Tracking** â€” Tracks facial landmarks and iris using MediaPipe.  
- ğŸ§  **Hybrid Fusion Engine** â€” Combines head pose and eye gaze vectors for robust gaze estimation.  
- âš™ï¸ **Calibration Modes**
  - **Point Calibration** (Manual)
  - **Automatic Calibration** (Adaptive)
- ğŸ“Š **Visualization** â€” Displays gaze direction and calibration feedback in real time.  
- ğŸª¶ **Lightweight** â€” CPU-optimized, runs on standard webcams.  
- ğŸ“ **Data Logging** â€” Optional CSV logging for gaze data analysis.  

---

## ğŸ§© System Architecture

```mermaid
flowchart TD
    A[Camera Input] --> B[MediaPipe Face Mesh]
    B --> C[Landmark Extraction]
    C --> D[Head Pose Estimation]
    C --> E[Eye Feature Extraction]
    C --> F[Iris Detection]
    D --> G[Head Gaze Vector]
    E --> H[Eye Gaze Vector]
    F --> H
    G --> I[Hybrid Fusion Engine]
    H --> I
    I --> J[Gaze Estimation Output]
    J --> K[Visualization and Logging]
```

---

## ğŸ› ï¸ Installation

### Step 1 â€“ Clone the Repository
```bash
git clone https://github.com/yourusername/gaze-tracking-system.git
cd gaze-tracking-system
```

### Step 2 â€“ Create Virtual Environment (Optional)
```bash
python -m venv venv
# Activate it
venv\Scripts\activate        # On Windows
source venv/bin/activate     # On macOS/Linux
```

### Step 3 â€“ Install Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ“¦ Requirements

Your `requirements.txt` should contain:
```
opencv-python
mediapipe
numpy
```

**Optional (for data logging and analysis):**
```
pandas
matplotlib
scikit-learn
scipy
```

---

## â–¶ï¸ Usage

### Run the Gaze Tracker
```bash
python gaze_tracker.py
```

### Keyboard Controls

| Key | Action |
|-----|---------|
| `c` | Start/Stop Calibration |
| `m` | Manual Point Calibration |
| `a` | Automatic Calibration |
| `q` | Quit Program |

---

## ğŸ§  Working Principle

1. **Face Detection** â€” MediaPipe detects 3D facial landmarks and iris positions.  
2. **Head Pose Estimation** â€” Calculates head orientation using selected landmarks.  
3. **Eye Gaze Vector** â€” Derived from iris center and eye corners.  
4. **Hybrid Fusion** â€” Merges head and eye gaze for stable tracking.  
5. **Calibration** â€” Maps gaze direction to screen coordinates.  
6. **Visualization** â€” Displays tracking overlay and calibration points.  

---

## ğŸ—‚ï¸ Folder Structure

```
ğŸ“ gaze-tracking-system
â”‚
â”œâ”€â”€ gaze_tracker.py           # Main script
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ README.md                 # Documentation
â””â”€â”€ utils/
    â”œâ”€â”€ calibration.py        # Calibration module
    â”œâ”€â”€ fusion.py             # Hybrid fusion logic
    â”œâ”€â”€ visualization.py      # Real-time display
    â””â”€â”€ logger.py             # Optional data logging
```

---

## ğŸŒŸ Future Enhancements

- ğŸ”¥ Heatmap visualization for gaze concentration  
- ğŸ“ˆ Real-time analytics dashboard  
- ğŸ§© Deep learningâ€“based gaze refinement  
- ğŸ’» Web-based gaze tracking (WebGazer.js integration)  
- ğŸ¯ Eye-controlled UI navigation  

---

## ğŸ§‘â€ğŸ’» Author

**Bala Ji**  
ğŸ’¼ Victo Hosting | Victo Interns  
ğŸŒ [victointern.site](https://victointern.site)

---

## ğŸ“„ License

Licensed under the **MIT License**.  
You may use, modify, and distribute this project with attribution.

---

## ğŸ™Œ Acknowledgements

- [MediaPipe by Google](https://developers.google.com/mediapipe)  
- [OpenCV](https://opencv.org/)  
- [WebGazer.js](https://webgazer.cs.brown.edu/) â€“ concept inspiration  

---

â­ **If you found this project useful, please give it a star on GitHub!**
